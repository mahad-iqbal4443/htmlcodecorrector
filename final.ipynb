{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Importing necessary libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Preparing the dataset\n",
    "data = [\n",
    "   (\"<em>This is emphasized text</em>\", \"<i>This is emphasized text</i>\"),\n",
    "(\"<i>This is italicized text</i>\", \"<em>This is italicized text</em>\"),\n",
    "(\"<strong>Bold and strong</strong>\", \"<b>Bold and strong</b>\"),\n",
    "(\"<u>This is underlined</u>\", \"<span style='text-decoration: underline;'>This is underlined</span>\"),\n",
    "(\"<s>This is strikethrough</s>\", \"<del>This is strikethrough</del>\"),\n",
    "(\"<sup>Superscript</sup>\", \"<sup>Superscript</sup>\"),\n",
    "(\"<sub>Subscript</sub>\", \"<sub>Subscript</sub>\"),\n",
    "(\"<mark>Highlighted text</mark>\", \"<span style='background-color: yellow;'>Highlighted text</span>\"),\n",
    "(\"<abbr title='Hypertext Markup Language'>HTML</abbr>\", \"<abbr title='Hypertext Markup Language'>HTML</abbr>\"),\n",
    "(\"<cite>Book title</cite>\", \"<cite>Book title</cite>\"),\n",
    "(\"<ul><li>Item 1</li><li>Item 2</li></ul>\", \"<ol><li>Item 1</li><li>Item 2</li></ol>\"),\n",
    "(\"<ol><li>Item 1</li><li>Item 2</li></ol>\", \"<ul><li>Item 1</li><li>Item 2</li></ul>\"),\n",
    "(\"<dl><dt>Term 1</dt><dd>Definition 1</dd><dt>Term 2</dt><dd>Definition 2</dd></dl>\", \"<table><tr><td>Term 1</td><td>Definition 1</td></tr><tr><td>Term 2</td><td>Definition 2</td></tr></table>\"),\n",
    "(\"<li>List item</li>\", \"<li style='list-style-type: none;'>List item</li>\"),\n",
    "(\"<blockquote>Blockquote text</blockquote>\", \"<q>Blockquote text</q>\"),\n",
    "(\"<hr>\", \"<hr style='border: 2px solid black;'>\"),\n",
    "(\"<pre>Preformatted text</pre>\", \"<code>Preformatted text</code>\"),\n",
    "(\"<address>Contact us at: <a href='mailto:info@example.com'>info@example.com</a></address>\", \"<p>Contact us at: <a href='mailto:info@example.com'>info@example.com</a></p>\"),\n",
    "(\"<button>Click me</button>\", \"<button disabled>Click me</button>\"),\n",
    "(\"<input type='text' placeholder='Enter text'>\", \"<textarea placeholder='Enter text'></textarea>\"),\n",
    "(\"<a href='https://www.example.com'>Visit our website</a>\", \"<a href='https://www.example.com' target='_blank'>Visit our website</a>\"),\n",
    "(\"<a href='#section1'>Link to Section 1</a>\", \"<a href='#section1' id='section1-link'>Link to Section 1</a>\"),\n",
    "(\"<img src='image.jpg' alt='Description of image'>\", \"<figure><img src='image.jpg' alt='Description of image'><figcaption>Caption for image</figcaption></figure>\"),\n",
    "(\"<audio controls><source src='audio.mp3' type='audio/mp3'></audio>\", \"<audio controls><source src='audio.mp3' type='audio/mp3'>Your browser does not support the audio element.</audio>\"),\n",
    "(\"<video controls><source src='video.mp4' type='video/mp4'></video>\", \"<video controls><source src='video.mp4' type='video/mp4'>Your browser does not support the video element.</video>\"),\n",
    "(\"<iframe src='https://www.youtube.com' width='560' height='315'></iframe>\", \"<iframe src='https://www.youtube.com/embed/VIDEO_ID' width='560' height='315'></iframe>\"),\n",
    "(\"<progress value='50' max='100'></progress>\", \"<progress value='50' max='100'></progress>\"),\n",
    "(\"<details><summary>Show details</summary>Details content</details>\", \"<details open><summary>Show details</summary>Details content</details>\"),\n",
    "(\"<nav><a href='#'>Home</a><a href='#about'>About</a></nav>\", \"<ul class='navigation'><li><a href='#'>Home</a></li><li><a href='#about'>About</a></li></ul>\"),\n",
    "(\"<time datetime='2023-01-01'>January 1, 2023</time>\", \"<time datetime='2023-01-01'>January 1, 2023</time>\"),\n",
    "(\"<h2>This is a subheading</h2>\", \"<h2 class='sub-heading'>This is a subheading</h2> In Style.css .sub-heading{color:Red;}\"),\n",
    "(\"<h3>Another subheading</h3>\", \"<h3 class='sub-heading'>Another subheading</h3> In Style.css .sub-heading{color:Blue;}\"),\n",
    "(\"<h4>Yet another subheading</h4>\", \"<h4 class='sub-heading'>Yet another subheading</h4> In Style.css .sub-heading{color:Green;}\"),\n",
    "(\"<h5>Subheading five</h5>\", \"<h5 class='sub-heading'>Subheading five</h5> In Style.css .sub-heading{color:Purple;}\"),\n",
    "(\"<h6>The smallest subheading</h6>\", \"<h6 class='sub-heading'>The smallest subheading</h6> In Style.css .sub-heading{color:Orange;}\"),\n",
    "(\"<header>Header content</header>\", \"<header><h1>Header content</h1></header>\"),\n",
    "(\"<footer>Footer content</footer>\", \"<footer><p>Footer content</p></footer>\"),\n",
    "(\"<main>Main content</main>\", \"<main><article>Main content</article></main>\"),\n",
    "(\"<section>Section content</section>\", \"<section id='section1'>Section content</section>\"),\n",
    "(\"<aside>Additional content</aside>\", \"<aside>Additional content</aside>\"),\n",
    "(\"<font size='3'>This is some text</font>\", \"<p class='text-size-3'>This is some text</p>\"),\n",
    "(\"<span style='color: red;'>Red text</span>\", \"<p style='color: red;'>Red text</p>\"),\n",
    "(\"<span style='background-color: yellow;'>Yellow background</span>\", \"<p style='background-color: yellow;'>Yellow background</p>\"),\n",
    "(\"<span style='font-family: Arial;'>Arial font</span>\", \"<p style='font-family: Arial;'>Arial font</p>\"),\n",
    "(\"<span style='text-transform: uppercase;'>Uppercase text</span>\", \"<p style='text-transform: uppercase;'>Uppercase text</p>\"),\n",
    "(\"<span style='text-align: center;'>Center-aligned text</span>\", \"<p style='text-align: center;'>Center-aligned text</p>\"),\n",
    "(\"<div style='border: 1px solid black;'>Div with border</div>\", \"<div style='border: 1px solid black; padding: 10px;'>Div with border and padding</div>\"),\n",
    "(\"<div style='margin: 20px;'>Div with margin</div>\", \"<div style='margin: 20px; background-color: #eee;'>Div with margin and background</div>\"),\n",
    "(\"<div style='width: 200px; height: 100px;'>Div with fixed size</div>\", \"<div style='width: 50%; height: 50px;'>Div with percentage width and fixed height</div>\"),\n",
    "(\"<div style='position: absolute; top: 10px; left: 20px;'>Absolute positioning</div>\", \"<div style='position: relative; top: 10px; left: 20px;'>Relative positioning</div>\"),\n",
    "(\"<div id='header'>Header content</div>\", \"<header><h1>Header content</h1></header>\"),\n",
    "(\"<div class='container'>Page content</div>\", \"<div class='wrapper'>Page content</div>\"),\n",
    "(\"<div id='sidebar'>Sidebar content</div>\", \"<aside id='sidebar'>Sidebar content</aside>\"),\n",
    "(\"<div class='clearfix'>Clearing floats</div>\", \"<div style='clear: both;'>Clearing floats alternative</div>\"),\n",
    "(\"<div class='centered'>Centered content</div>\", \"<div style='margin: 0 auto; width: 80%;'>Centered content alternative</div>\"),\n",
    "(\"<div class='hidden'>Hidden content</div>\", \"<div style='display: none;'>Hidden content alternative</div>\"),\n",
    "(\"<div class='visible'>Visible content</div>\", \"<div style='display: block;'>Visible content alternative</div>\"),\n",
    "(\"<div class='hover-effect'>Hover effect</div>\", \"<div class='hover-effect' onmouseover='this.style.color=\\\"red\\\"' onmouseout='this.style.color=\\\"black\\\"'>Hover effect alternative</div>\"),\n",
    "(\"<div class='rotate'>Rotated content</div>\", \"<div class='rotate' style='transform: rotate(45deg);'>Rotated content alternative</div>\"),\n",
    "(\"<div class='gradient-bg'>Gradient background</div>\", \"<div class='gradient-bg' style='background: linear-gradient(to right, #ffcc00, #ff6600);'>Gradient background alternative</div>\"),\n",
    "(\"<!DOCTYPE HTML PUBLIC \\\"-//W3C//DTD HTML 4.01 Transitional//EN\\\">\", \"<!DOCTYPE html>\"),\n",
    "(\"<!DOCTYPE html>\", \"<!DOCTYPE html>\"),\n",
    "(\"<!DOCTYPE html>\", \"<!DOCTYPE html>\\n<html lang='en'>\"),\n",
    "(\"<!DOCTYPE html>\", \"<!DOCTYPE html>\\n<html lang='en'>\\n<head>\\n<meta charset='UTF-8'>\\n<meta name='viewport' content='width=device-width, initial-scale=1.0'>\\n<title>My Web Page</title>\\n</head>\\n<body>\\n<h1>Hello, World!</h1>\\n</body>\\n</html>\"),\n",
    "(\"<html>\", \"<html lang='en'>\"),\n",
    "(\"<html lang='en'>\", \"<html lang='en' dir='ltr'>\"),\n",
    "(\"<head>\", \"<head>\\n<meta name='description' content='Description of your web page'>\"),\n",
    "(\"<meta charset='UTF-8'>\", \"<meta charset='UTF-8'>\\n<meta name='author' content='Your Name'>\"),\n",
    "(\"<title>My Web Page</title>\", \"<title>My Awesome Web Page</title>\"),\n",
    "(\"<link rel='stylesheet' href='styles.css'>\", \"<link rel='stylesheet' href='styles.css'>\"),\n",
    "(\"<script src='script.js'></script>\", \"<script defer src='script.js'></script>\"),\n",
    "]\n",
    "\n",
    "# Spliting the data into input (X) and target (y)\n",
    "X, y = zip(*data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Tokenizing the text data\n",
    "tokenizer_X = Tokenizer(filters='')\n",
    "tokenizer_X.fit_on_texts(X)\n",
    "X_seqs = tokenizer_X.texts_to_sequences(X)\n",
    "\n",
    "tokenizer_y = Tokenizer(filters='')\n",
    "tokenizer_y.fit_on_texts(y)\n",
    "y_seqs = tokenizer_y.texts_to_sequences(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Padding the sequences to have the same length\n",
    "X_pad = pad_sequences(X_seqs)\n",
    "y_pad = pad_sequences(y_seqs, maxlen=X_pad.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: `Spliting` the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pad, y_pad, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Building the sequence-to-sequence model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(tokenizer_X.word_index) + 1, output_dim=256, input_length=X_pad.shape[1]),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(512, return_sequences=True)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(512, return_sequences=True)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(len(tokenizer_y.word_index) + 1, activation='softmax'))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 2s 586ms/step - loss: 0.9796 - accuracy: 0.8551 - val_loss: 4.9665 - val_accuracy: 0.4688\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 2s 548ms/step - loss: 0.7200 - accuracy: 0.8665 - val_loss: 4.9457 - val_accuracy: 0.4688\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 2s 558ms/step - loss: 0.4688 - accuracy: 0.8750 - val_loss: 4.9146 - val_accuracy: 0.4688\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 2s 532ms/step - loss: 0.3299 - accuracy: 0.9290 - val_loss: 4.8971 - val_accuracy: 0.4688\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 2s 555ms/step - loss: 0.2893 - accuracy: 0.9375 - val_loss: 4.8909 - val_accuracy: 0.4688\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 2s 524ms/step - loss: 0.2482 - accuracy: 0.9517 - val_loss: 4.8844 - val_accuracy: 0.4688\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 2s 547ms/step - loss: 0.1917 - accuracy: 0.9602 - val_loss: 4.8717 - val_accuracy: 0.4688\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 2s 550ms/step - loss: 0.1580 - accuracy: 0.9801 - val_loss: 4.8597 - val_accuracy: 0.4688\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 2s 536ms/step - loss: 0.1546 - accuracy: 0.9631 - val_loss: 4.8449 - val_accuracy: 0.4688\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 2s 538ms/step - loss: 0.1434 - accuracy: 0.9716 - val_loss: 4.8295 - val_accuracy: 0.4583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1dfc2284c70>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 7: Training the model\n",
    "model.fit(X_train, np.expand_dims(y_train, -1), epochs=10, batch_size=16, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Saving the tokenizer configuration\n",
    "with open('tokenizer_X_config.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer_X.get_config(), handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer_y_config.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer_y.get_config(), handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Window\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Saving the model\n",
    "model.save('html_correction_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('html_correction_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import pickle\n",
    "\n",
    "# Loading Tokenizer Configurations\n",
    "with open('tokenizer_X_config.pickle', 'rb') as handle:\n",
    "    tokenizer_X_config = pickle.load(handle)\n",
    "\n",
    "loaded_tokenizer_X = Tokenizer()\n",
    "loaded_tokenizer_X.word_index = tokenizer_X_config['word_index']\n",
    "loaded_tokenizer_X.document_count = tokenizer_X_config['document_count']\n",
    "loaded_tokenizer_X.char_level = tokenizer_X_config['char_level']  # Add this line\n",
    "loaded_tokenizer_X.oov_token = tokenizer_X_config['oov_token'] \n",
    "\n",
    "\n",
    "# Repeating the same process for the 'tokenizer_y' as well\n",
    "with open('tokenizer_Y_config.pickle', 'rb') as handle:\n",
    "    tokenizer_Y_config = pickle.load(handle)\n",
    "\n",
    "loaded_tokenizer_Y = Tokenizer()\n",
    "loaded_tokenizer_Y.word_index = tokenizer_Y_config['word_index']\n",
    "loaded_tokenizer_Y.document_count = tokenizer_Y_config['document_count']\n",
    "loaded_tokenizer_Y.char_level = tokenizer_Y_config['char_level']\n",
    "loaded_tokenizer_Y.oov_token = tokenizer_Y_config['oov_token']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32me:\\Greenie Task\\Final\\final.ipynb Cell 15\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Greenie%20Task/Final/final.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m input_text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m<em>This is emphasized text</em>\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Greenie%20Task/Final/final.ipynb#X32sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Tokenize the input text\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Greenie%20Task/Final/final.ipynb#X32sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m input_seq \u001b[39m=\u001b[39m loaded_tokenizer_X\u001b[39m.\u001b[39;49mtexts_to_sequences([input_text])\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Greenie%20Task/Final/final.ipynb#X32sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Pad the sequence to match the model input length\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Greenie%20Task/Final/final.ipynb#X32sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m input_pad \u001b[39m=\u001b[39m pad_sequences(input_seq, maxlen\u001b[39m=\u001b[39mX_pad\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Window\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\preprocessing\\text.py:357\u001b[0m, in \u001b[0;36mTokenizer.texts_to_sequences\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtexts_to_sequences\u001b[39m(\u001b[39mself\u001b[39m, texts):\n\u001b[0;32m    346\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Transforms each text in texts to a sequence of integers.\u001b[39;00m\n\u001b[0;32m    347\u001b[0m \n\u001b[0;32m    348\u001b[0m \u001b[39m    Only top `num_words-1` most frequent words will be taken into account.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[39m        A list of sequences.\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 357\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtexts_to_sequences_generator(texts))\n",
      "File \u001b[1;32mc:\\Users\\Window\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\preprocessing\\text.py:375\u001b[0m, in \u001b[0;36mTokenizer.texts_to_sequences_generator\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Transforms each text in `texts` to a sequence of integers.\u001b[39;00m\n\u001b[0;32m    361\u001b[0m \n\u001b[0;32m    362\u001b[0m \u001b[39mEach item in texts can also be a list,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[39m    Yields individual sequences.\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    374\u001b[0m num_words \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_words\n\u001b[1;32m--> 375\u001b[0m oov_token_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mword_index\u001b[39m.\u001b[39;49mget(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moov_token)\n\u001b[0;32m    376\u001b[0m \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m texts:\n\u001b[0;32m    377\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchar_level \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(text, \u001b[39mlist\u001b[39m):\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "# Assuming I have a new input text\n",
    "input_text = \"<em>This is emphasized text</em>\"\n",
    "\n",
    "# Tokenizing the input text\n",
    "input_seq = loaded_tokenizer_X.texts_to_sequences([input_text])\n",
    "\n",
    "# Padding the sequence to match the model input length\n",
    "input_pad = pad_sequences(input_seq, maxlen=X_pad.shape[1])\n",
    "\n",
    "# Making predictions using the loaded model\n",
    "predictions = loaded_model.predict(input_pad)\n",
    "\n",
    "# Converting predictions to sequences\n",
    "predicted_seq = np.argmax(predictions, axis=-1)[0]\n",
    "\n",
    "# Converting the predicted sequence back to text using the loaded tokenizer\n",
    "predicted_text = loaded_tokenizer_Y.sequences_to_texts([predicted_seq])[0]\n",
    "\n",
    "# Printing the original input and the predicted output\n",
    "print(\"Original Input Text:\", input_text)\n",
    "print(\"Predicted Output Text:\", predicted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = loaded_model.predict(input_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_seq = np.argmax(predictions, axis=-1)[0]\n",
    "predicted_text = loaded_tokenizer_y.sequences_to_texts([predicted_seq])[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
